{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# pneumonia mnist resnet18 (colab ready)\n\nsimple end to end notebook for training and explaining a resnet18 on pneumonia mnist.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## setup\n\n* switch runtime to gpu in colab (runtime > change runtime type > gpu)\n* mount drive so checkpoints and figures are saved\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# mount google drive to keep outputs\nfrom google.colab import drive\ndrive.mount('/gdrive')\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# install needed libraries (torch + medmnist + shap)\n# keep versions explicit so results are repeatable\n!pip install --quiet torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2\n!pip install --quiet medmnist==2.2.2 shap==0.44.1 scikit-learn==1.3.2 matplotlib==3.8.2 seaborn==0.13.1\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# imports\nimport os\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms, models\nfrom sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve\nimport medmnist\nfrom medmnist import PneumoniaMNIST\nimport shap\n\n# make runs repeatable\nrandom.seed(7)\nnp.random.seed(7)\ntorch.manual_seed(7)\ntorch.cuda.manual_seed_all(7)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('device:', device)\n\n# folder to save checkpoints and plots inside drive\noutput_dir = '/gdrive/MyDrive/pneumonia_mnist_resnet18'\nos.makedirs(output_dir, exist_ok=True)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## data\n\npneumonia mnist is already preprocessed. we just load it with medmnist and add a simple normalization.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# transforms keep channel as single grayscale image\nimg_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5], std=[0.5]),\n])\n\ntrain_ds = PneumoniaMNIST(split='train', download=True, transform=img_transform)\nval_ds = PneumoniaMNIST(split='val', download=True, transform=img_transform)\ntest_ds = PneumoniaMNIST(split='test', download=True, transform=img_transform)\n\nbatch_size = 128\ntrain_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=2)\ntest_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=2)\n\nnum_classes = len(set(train_ds.labels.reshape(-1).tolist()))\nprint('classes:', num_classes)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## model helper\n\nwe use torchvision resnet18 with imagenet weights. first conv is adjusted for 1 channel images. transfer learning happens by choosing which blocks to freeze.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def build_resnet18(freeze_parts=None):\n",
        "    # load imagenet pretrained weights\n",
        "    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "    # change first conv to accept 1 channel\n",
        "    base_conv = model.conv1\n",
        "    model.conv1 = nn.Conv2d(1, base_conv.out_channels, kernel_size=base_conv.kernel_size,\n",
        "                            stride=base_conv.stride, padding=base_conv.padding, bias=False)\n",
        "    # average weights of original channels to init\n",
        "    with torch.no_grad():\n",
        "        model.conv1.weight = nn.Parameter(base_conv.weight.mean(dim=1, keepdim=True))\n",
        "\n",
        "    # swap final layer to binary head\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "    # freeze selected parts\n",
        "    if freeze_parts:\n",
        "        for name, param in model.named_parameters():\n",
        "            for block_name in freeze_parts:\n",
        "                if name.startswith(block_name):\n",
        "                    param.requires_grad = False\n",
        "                    break\n",
        "    return model\n",
        "\n",
        "# examples of freeze configurations\n",
        "freeze_configs = [\n",
        "    {'label': 'freeze_to_layer3', 'freeze_parts': ['conv1', 'bn1', 'layer1', 'layer2', 'layer3']},\n",
        "    {'label': 'freeze_to_layer2', 'freeze_parts': ['conv1', 'bn1', 'layer1', 'layer2']},\n",
        "    {'label': 'full_finetune', 'freeze_parts': []},\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## training utils\n\nsimple training + validation loops that track best checkpoint per config.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "def run_epoch(model, loader, criterion, optimizer=None):\n    model.train() if optimizer else model.eval()\n    running_loss = 0.0\n    preds, targets = [], []\n\n    for images, labels in loader:\n        images = images.to(device)\n        labels = labels.squeeze().long().to(device)\n\n        if optimizer:\n            optimizer.zero_grad()\n\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        running_loss += loss.item() * images.size(0)\n\n        if optimizer:\n            loss.backward()\n            optimizer.step()\n\n        pred_labels = torch.argmax(outputs, dim=1)\n        preds.extend(pred_labels.detach().cpu().numpy())\n        targets.extend(labels.detach().cpu().numpy())\n\n    avg_loss = running_loss / len(loader.dataset)\n    acc = accuracy_score(targets, preds)\n    return avg_loss, acc\n\n\ndef train_one_setting(label, freeze_parts, epochs=8, lr=1e-3):\n    print(f'\n>>> training config: {label}')\n    model = build_resnet18(freeze_parts).to(device)\n\n    # only update trainable params\n    optim_params = [p for p in model.parameters() if p.requires_grad]\n    optimizer = optim.Adam(optim_params, lr=lr, weight_decay=1e-4)\n    criterion = nn.CrossEntropyLoss()\n\n    best_val_acc = 0.0\n    best_path = os.path.join(output_dir, f'{label}_best.pt')\n\n    for epoch in range(1, epochs + 1):\n        train_loss, train_acc = run_epoch(model, train_loader, criterion, optimizer)\n        val_loss, val_acc = run_epoch(model, val_loader, criterion)\n        print(f'epoch {epoch}: train_loss {train_loss:.4f} acc {train_acc:.4f} | val_loss {val_loss:.4f} acc {val_acc:.4f}')\n\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save(model.state_dict(), best_path)\n            print('saved new best model')\n    return best_path, best_val_acc\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## run transfer learning experiments\n\ntrain with different freeze depths to see what works best. adjust epochs upward if the gpu session is stable.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "results = []\nfor cfg in freeze_configs:\n    ckpt, val_acc = train_one_setting(cfg['label'], cfg['freeze_parts'], epochs=10, lr=1e-3)\n    results.append({'label': cfg['label'], 'val_acc': val_acc, 'ckpt': ckpt})\n\n# pick best config\nresults = sorted(results, key=lambda x: x['val_acc'], reverse=True)\nbest = results[0]\nprint('\nbest config:', best)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## evaluation on test set\n\nload the best checkpoint, evaluate, and draw confusion matrix + roc curve.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# load best model\nbest_model = build_resnet18()\nbest_model.load_state_dict(torch.load(best['ckpt'], map_location=device))\nbest_model.to(device)\nbest_model.eval()\n\n# collect outputs\nall_logits, all_targets = [], []\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images = images.to(device)\n        labels = labels.squeeze().long().to(device)\n        logits = best_model(images)\n        all_logits.append(logits.cpu())\n        all_targets.append(labels.cpu())\n\nlogits = torch.cat(all_logits)\ntargets = torch.cat(all_targets)\nprobs = torch.softmax(logits, dim=1)[:, 1]\npred_labels = torch.argmax(logits, dim=1)\n\nacc = accuracy_score(targets, pred_labels)\ncm = confusion_matrix(targets, pred_labels)\n\nfpr, tpr, _ = roc_curve(targets, probs)\nroc_auc = roc_auc_score(targets, probs)\n\nprint('test accuracy:', acc)\nprint('roc auc:', roc_auc)\n\n# plot confusion matrix\nplt.figure(figsize=(5,4))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\nplt.xlabel('predicted')\nplt.ylabel('true')\nplt.title('confusion matrix')\ncm_path = os.path.join(output_dir, 'confusion_matrix.png')\nplt.savefig(cm_path, dpi=150, bbox_inches='tight')\nplt.show()\n\n# plot roc curve\nplt.figure(figsize=(5,4))\nplt.plot(fpr, tpr, label=f'auc={roc_auc:.3f}')\nplt.plot([0,1],[0,1],'k--')\nplt.xlabel('false positive rate')\nplt.ylabel('true positive rate')\nplt.title('roc curve')\nplt.legend()\nroc_path = os.path.join(output_dir, 'roc_curve.png')\nplt.savefig(roc_path, dpi=150, bbox_inches='tight')\nplt.show()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## shap gradient explainer\n\nuse a small background batch for the gradient explainer. we look at one correct and one incorrect prediction (from different classes) to see what pixels drive the decision.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# pick background samples\n",
        "background_images, _ = next(iter(train_loader))\n",
        "background_images = background_images[:50].to(device)\n",
        "\n",
        "# prepare explainer\n",
        "grad_explainer = shap.GradientExplainer(best_model, background_images)\n",
        "\n",
        "# find correct and incorrect examples\n",
        "best_model.eval()\n",
        "correct_example = None\n",
        "incorrect_example = None\n",
        "\n",
        "for images, labels in test_loader:\n",
        "    images = images.to(device)\n",
        "    labels = labels.squeeze().long().to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = best_model(images)\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "    for img, label, pred in zip(images, labels, preds):\n",
        "        if correct_example is None and pred == label:\n",
        "            correct_example = (img.unsqueeze(0), label.item(), pred.item())\n",
        "        if incorrect_example is None and pred != label:\n",
        "            incorrect_example = (img.unsqueeze(0), label.item(), pred.item())\n",
        "        if correct_example and incorrect_example:\n",
        "            break\n",
        "    if correct_example and incorrect_example:\n",
        "        break\n",
        "\n",
        "examples = {'correct_case': correct_example, 'incorrect_case': incorrect_example}\n",
        "\n",
        "for tag, sample in examples.items():\n",
        "    if sample is None:\n",
        "        print(f'skipping {tag} because it was not found')\n",
        "        continue\n",
        "    img, true_label, pred_label = sample\n",
        "    shap_values = grad_explainer.shap_values(img)\n",
        "    shap.image_plot(shap_values, img.cpu().numpy(), show=False)\n",
        "    plt.title(f'{tag} true={true_label} pred={pred_label}')\n",
        "    fig_path = os.path.join(output_dir, f'{tag}_shap.png')\n",
        "    plt.savefig(fig_path, dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## notes for the report\n\n* keep an eye on whether freezing more layers hurts validation accuracy. usually unfreezing layer4 helps.\n* confusion matrix shows where false positives/negatives happen.\n* shap maps highlight lung regions that push decisions; noisy edges suggest overfitting.\n* store your favorite checkpoint and figures in drive for later write-up.\n"
    }
  ]
}